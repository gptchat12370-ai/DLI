{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gptchat12370-ai/DLI/blob/main/2_feature_engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikl4ZNFOhTbA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a9d5fab-e4fc-4507-c6dd-6d60780910fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DLI'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 6 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (6/6), 8.30 KiB | 1.19 MiB/s, done.\n",
            "/content/DLI\n"
          ]
        }
      ],
      "source": [
        "!git config --global user.email \"almnaryb139@gmail.com\"\n",
        "!git config --global user.name \"shihab1\"\n",
        "\n",
        "!git clone https://github.com/shihab1/DLI.git\n",
        "%cd DLI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Commit 1: Text cleaning and preprocessing ---\n",
        "\n",
        "# 1. Setup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')  # Optional: kept for future use\n",
        "\n",
        "# 2. Load cleaned dataset from previous step\n",
        "df = pd.read_csv(\"data/cleaned_data.csv\")\n",
        "\n",
        "# 3. Merge subject and body into one text column\n",
        "df['text'] = df['subject'].fillna('') + ' ' + df['body'].fillna('')\n",
        "\n",
        "# 4. Phishing-aware text cleaner\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "\n",
        "    # Replace URLs with placeholder\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', ' httpurl ', text)\n",
        "\n",
        "    # Replace email addresses\n",
        "    text = re.sub(r'\\S+@\\S+', ' emailaddr ', text)\n",
        "\n",
        "    # Replace money patterns\n",
        "    text = re.sub(r'\\$\\d+|\\d+%', ' moneytoken ', text)\n",
        "\n",
        "    # Keep useful symbols (emails, links) and remove others\n",
        "    text = re.sub(r'[^a-zA-Z0-9@:\\./\\s]', '', text)\n",
        "\n",
        "    # Normalize extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "# 5. Apply cleaning\n",
        "df['clean_text'] = df['text'].apply(clean_text)\n",
        "\n",
        "# Adding real-world safe emails to improve model generalization\n",
        "extra_emails = [\n",
        "     \"Hey Alex, are you free for coffee next week?\",\n",
        "     \"Thanks again for your help!\",\n",
        "     \"Just checking in. Hope you're doing well!\",\n",
        "     \"Can we reschedule our meeting?\",\n",
        "     \"Hope everything is going great with you!\"\n",
        " ]\n",
        "extra_labels = [0] * len(extra_emails)\n",
        "df_extra = pd.DataFrame({'subject': '', 'body': extra_emails, 'label': extra_labels})\n",
        "df_extra['text'] = df_extra['subject'] + ' ' + df_extra['body']\n",
        "df_extra['clean_text'] = df_extra['text'].apply(clean_text)\n",
        "df = pd.concat([df, df_extra], ignore_index=True)\n",
        "\n",
        "print(\"Cleaned text sample:\")\n",
        "print(df[['text', 'clean_text']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ynz3Fu5BOgdy",
        "outputId": "bf82b998-2924-4baa-adad-7434eed51e7c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned text sample:\n",
            "                                                text  \\\n",
            "0  FW: June 29 -- BNA, Inc. Daily Labor Report Us...   \n",
            "1  NGX failover plan. Hi Chris, Tonight we are ro...   \n",
            "2  RE: Intranet Site Rika r these new? -----Origi...   \n",
            "3  FW: ENA Upstream Company information John/Gera...   \n",
            "4  New Master Physical Gerald and Stacy - Attache...   \n",
            "\n",
            "                                          clean_text  \n",
            "0  fw: june 29 bna inc. daily labor report user i...  \n",
            "1  ngx failover plan. hi chris tonight we are rol...  \n",
            "2  re: intranet site rika r these new original me...  \n",
            "3  fw: ena upstream company information john/gera...  \n",
            "4  new master physical gerald and stacy attached ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Commit 2: Tokenization and sequence preparation ---\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pickle\n",
        "\n",
        "# 6. Fit tokenizer on clean text\n",
        "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(df['clean_text'])\n",
        "\n",
        "# 7. Convert to sequences and pad\n",
        "sequences = tokenizer.texts_to_sequences(df['clean_text'])\n",
        "X = pad_sequences(sequences, maxlen=200)\n",
        "\n",
        "# Save tokenizer\n",
        "with open(\"tokenizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "\n",
        "print(\"Sample tokenized sequence:\", sequences[0])\n",
        "print(\"Padded shape:\", X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAskOILFhIGI",
        "outputId": "fdfb9260-d222-4170-e8a9-fe0435c11840"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample tokenized sequence: [162, 754, 447, 4463, 97, 407, 2176, 111, 867, 522, 1, 1, 1, 56, 40, 15, 4463, 3071, 47, 188, 754, 399, 34, 80, 60, 93, 3, 4463, 3071, 46, 754, 447, 4463, 97, 407, 2176, 111, 407, 2176, 111, 3071, 1164, 5, 1675, 754, 447, 34, 8340, 1, 792, 375, 1255, 52, 292, 2, 454, 1202, 5, 90, 2464, 28, 536, 2, 2129, 550, 5659, 65, 71, 3028, 6, 3193, 19, 3045, 69, 8, 6, 122, 375, 2201, 9, 196, 25, 32, 19, 137, 4463, 443, 1955, 25, 1, 2074, 1966, 148, 180, 68, 143, 85, 93, 1499, 3071, 305, 184, 4326, 1, 8833, 845, 12, 9429, 2851, 3039, 6, 345, 1107, 150, 9429, 3039, 1, 1, 4, 9241, 1347, 4, 1, 1554, 4, 612, 298, 29, 3349, 7513, 2176, 2122, 2, 2057, 5, 2961, 4326, 956, 1, 6, 539, 2176, 1955, 489, 845, 1, 1, 1, 1, 517, 6, 97, 715, 8833, 305, 184, 6545, 54, 1, 152, 257, 63, 2, 489, 742, 2, 9429, 2851, 3039, 5, 1, 1, 1, 1452, 517, 6, 97, 1, 17, 468, 3209, 5, 88, 368, 218, 2, 539, 2176, 1955, 414, 2, 489, 3582, 13, 6, 586, 4669, 16, 742, 3, 1690, 622, 1, 468, 7, 1, 2910, 896, 3, 16, 5294, 28, 2, 1, 1, 353, 2057, 1, 1, 5, 1417, 345, 2, 3307, 709, 4945, 27, 8475, 4299, 3, 1102, 1, 5330, 5, 2, 260, 8, 6, 48, 4669, 189, 27, 9, 29, 6, 203, 260, 2, 709, 1, 2, 4002, 505, 13, 2, 7981, 12, 1, 4, 9241, 1347, 42, 35, 7513, 2176, 650, 4659, 5, 622, 27, 1565, 1, 468, 3209, 5, 88, 368, 1637, 1, 4945, 2, 1, 2348, 9, 460, 189, 27, 106, 3858, 3, 2851, 276, 486, 78, 4, 7, 2, 238, 396, 4, 3858, 1397, 2, 489, 89, 27, 496, 16, 62, 3, 1, 153, 1, 1291, 19, 83, 4598, 1624, 469, 1, 1202, 8242, 32, 32, 9429, 1, 1635, 1, 1026, 1, 218, 8976, 6, 869, 443, 133, 7682, 8, 6, 5520, 82, 44, 4313, 138, 789, 1, 1635, 25, 238, 13, 698, 1, 15, 6, 933, 533, 42, 1479, 3, 3137, 13, 387, 1, 42, 6272, 218, 2, 2772, 17, 1, 414, 2, 5342, 4326, 956, 4300, 715, 1417, 380, 82, 524, 4291, 6545, 54, 1, 152, 257, 63, 8573, 217, 4300, 1402, 3, 744, 374, 42, 6, 3414, 1009, 218, 2, 414, 670, 13, 387, 6697, 1635, 123, 1, 17, 387, 953, 3, 1188, 443, 314, 1378, 71, 67, 19, 500, 1, 1637, 1, 4945, 1, 1101, 5108, 3, 1417, 380, 82, 524, 1, 92, 4945, 4300, 1, 6, 719, 2891, 3, 387, 4916, 189, 387, 706, 542, 3753, 2674, 2311, 5, 1, 190, 20, 67, 1, 4, 1, 82, 1332, 13, 123, 8132, 1300, 5970, 3, 2, 503, 469, 1, 32, 1, 1, 1973, 1, 3, 952, 17, 1, 1, 3, 2, 539, 2176, 3754, 5, 2, 570, 577, 1, 2, 2176, 3880, 5, 2, 577, 1, 1725, 1, 1973, 3, 952, 17, 2, 1, 33, 37, 1688, 20, 1806, 2, 1, 5, 2, 1, 1831, 23, 711, 878, 848, 50, 340, 27, 1591, 77, 55, 1, 57, 110, 3, 16, 5365, 187, 2, 1, 70, 36, 66, 7, 2, 950, 8, 55, 120, 6, 132, 3965, 6, 4800, 2, 9583, 693, 5, 1, 9, 876, 3, 1973, 754, 180, 12, 6, 1, 241, 13, 58, 1125, 41, 271, 1, 1725, 13, 1, 7, 8612, 8207, 3, 16, 6, 800, 5, 1, 186, 558, 255, 11, 42, 6, 3080, 5, 2, 1, 1, 6, 8104, 27, 9, 3718, 622, 2, 1, 241, 23, 1003, 4, 33, 27, 287, 29, 102, 3460, 3, 2, 1, 209, 469, 1, 32, 48, 261, 472, 6233, 1, 15, 4599, 769, 709, 4945, 7, 6, 530, 5, 182, 8341, 6, 601, 2201, 709, 1, 6, 1, 14, 125, 2451, 9195, 1, 4530, 1648, 153, 48, 261, 472, 189, 27, 298, 29, 1, 1, 1, 1, 15, 1, 4530, 218, 2, 5732, 2134, 368, 1, 1, 715, 48, 261, 472, 117, 305, 517, 1080, 54, 147, 1, 1, 1, 152, 226, 63, 1, 2, 5992, 83, 1, 1, 340, 1637, 3561, 5, 2, 195, 117, 2057, 709, 8, 2, 1320, 2057, 5, 48, 261, 1, 2, 1, 1648, 5, 14, 583, 7, 1, 4530, 2, 709, 1, 2, 5732, 9664, 947, 13, 7432, 1, 1, 1402, 3, 176, 1185, 5, 2, 48, 261, 3258, 4158, 4247, 336, 2863, 13, 374, 42, 1, 129, 29, 855, 89, 189, 5, 1, 4, 1, 2029, 2, 709, 92, 1, 2, 5732, 1, 3232, 3, 2, 1, 5, 2, 4247, 469, 7538, 32, 1, 1, 5092, 20, 2390, 8, 1, 348, 7, 6, 1, 49, 1, 1813, 5, 2, 277, 1, 5, 1, 6957, 754, 399, 6786, 348, 485, 228, 1, 4, 1, 863, 1, 338, 21, 5092, 8, 2, 6925, 403, 181, 92, 5092, 21, 317, 1, 1, 863, 1, 4, 1, 1, 863, 1, 2, 933, 5, 1, 954, 1, 7, 6057, 1, 7053, 23, 1457, 676, 754, 399, 3, 1690, 33, 2, 2390, 307, 2, 1, 105, 373, 457, 8, 88, 926, 3, 16, 1361, 12, 2, 3434, 8, 2, 1214, 4669, 827, 2, 6925, 50, 121, 125, 597, 13, 1, 23, 246, 105, 373, 5, 2, 1, 5971, 9, 6, 1, 2825, 670, 91, 1, 457, 827, 2, 55, 120, 9584, 1, 1063, 5971, 12, 1134, 1, 4, 1, 4491, 1872, 3, 744, 13, 1, 36, 2, 457, 5, 106, 6, 388, 1638, 1, 7, 91, 586, 3232, 3, 1, 8, 2, 1831, 1, 340, 1, 4, 597, 5, 91, 1889, 1872, 3587, 51, 23, 84, 2, 5971, 773, 3, 16, 1361, 12, 2, 3434, 83, 597, 5, 1, 1, 915, 307, 55, 5971, 120, 773, 3, 16, 1361, 12, 2, 3434, 469, 8834, 32, 1, 1, 6640, 4916, 2130, 8, 612, 2, 95, 5, 848, 53, 23, 7134, 2, 2785, 5, 2, 1, 1543, 4, 1031, 8292, 1232, 6640, 2130, 5, 55, 120, 1, 5093, 4483, 3, 6958, 533, 4, 8058, 265, 3, 501, 756, 1, 5093, 2, 1533, 340, 23, 29, 347, 1468, 5093, 7, 2, 2055, 2130, 2, 34, 2130, 436, 7350, 1, 953, 3, 1766, 4, 756, 38, 1291, 12, 2, 55, 1, 1, 4946, 1, 3267, 572, 779, 1, 434, 2, 2130, 2039, 2306, 132, 354, 265, 1, 1, 288, 12, 2, 354, 265, 23, 29, 16, 4126, 378, 210, 19, 429, 5, 81, 2, 1, 1651, 434, 5093, 23, 16, 658, 3, 790, 3663, 8, 798, 2524, 649, 1621, 4, 6, 1101, 5, 2, 1, 4127, 4, 1, 13, 2535, 25, 88, 238, 1491, 7, 354, 2, 1533, 434, 2, 6466, 335, 16, 1832, 320, 33, 6, 1, 4916, 5311, 54, 1, 4127, 19, 1, 8, 354, 2, 1533, 434, 469, 7538, 32, 852, 546, 1, 586, 3936, 5, 3777, 2112, 382, 8, 2, 182, 573, 1348, 148, 180, 6, 217, 2814, 680, 92, 7, 2, 131, 5295, 6731, 2, 1, 2176, 99, 338, 2, 175, 5, 4062, 1, 546, 4, 2, 175, 5, 1888, 1178, 104, 2729, 764, 276, 2, 182, 707, 515, 5, 11, 132, 120, 7, 2, 415, 730, 5, 354, 2, 1, 546, 865, 8, 57, 2626, 1178, 6, 390, 5, 1, 1888, 469, 1, 32, 6172, 1477, 48, 1, 957, 1111, 17, 271, 1616, 1066, 8, 2, 563, 4632, 95, 280, 1, 3, 6, 1, 6467, 390, 5, 1, 8, 2, 95, 2688, 754, 300, 469, 1, 32, 1031, 1131, 468, 590, 1251, 21, 1, 3, 1, 2, 317, 790, 5, 1, 7, 2, 570, 380, 6, 716, 3289, 270, 706, 1, 555, 3, 2, 506, 775, 181, 469, 1, 32, 1910, 597, 5, 1089, 6925, 4134, 5382, 1888, 25, 8723, 7886, 365, 7, 3381, 7085, 21, 876, 3, 1973, 848, 152, 12, 6, 48, 7648, 198, 17, 2, 8723, 7886, 365, 524, 469, 9585, 32, 1202, 7513, 2176, 2122, 2057, 5, 2961, 4326, 845, 7, 1, 1, 1, 1452, 517, 6, 97, 715, 8833, 469, 8242, 32, 1164, 5, 1675, 1137, 2, 131, 7513, 2176, 2122, 1, 8833, 305, 184, 4326, 4945, 345, 1107, 9429, 3039, 1, 1, 4, 9241, 1347, 4, 1, 1554, 4, 612, 298, 29, 3349, 7513, 2176, 2122, 469, 1, 1202, 8242, 32, 32, 131, 1, 5342, 4326, 956, 869, 443, 133, 7682, 25, 5520, 82, 44, 4313, 138, 789, 1, 1635, 25, 238, 698, 697, 3, 933, 533, 1402, 3, 3137, 374, 42, 3414, 1009, 218, 8976, 469, 1, 32, 5869, 693, 1, 656, 1096, 3, 1973, 12, 412, 1160, 572, 143, 13, 58, 1128, 7683, 2212, 3, 3686, 8, 601, 6273, 213, 740, 2321, 15, 2648, 690, 13, 58, 7821, 953, 5, 190, 2212, 3, 1, 7, 2524, 469, 1, 32, 1036, 1702, 1, 1751, 1927, 4945, 345, 3005, 201, 1, 730, 281, 651, 5909, 1, 3813, 705, 626, 141, 25, 738, 81, 469, 7255, 32, 1910, 597, 5, 1089, 6925, 4134, 5382, 1888, 3, 1973, 848, 152, 12, 48, 7648, 198, 17, 8723, 7886, 365, 524, 469, 9585, 32, 1031, 1131, 1383, 3891, 1, 12, 2321, 3982, 3, 6839, 412, 5, 368, 2399, 49, 2762, 8, 1, 69, 238, 12, 412, 28, 605, 5, 1383, 94, 8, 540, 1872, 1, 469, 1, 32, 1031, 1131, 468, 1, 1, 706, 1, 20, 403, 827, 590, 1251, 1, 3, 1, 317, 790, 5, 1, 7, 570, 380, 469, 1, 32, 1, 5784, 437, 489, 4945, 726, 8, 2176, 1970, 7, 57, 20, 1, 1470, 893, 1066, 28, 105, 2895, 490, 15, 1659, 351, 3, 1448, 373, 469, 1, 32, 1543, 1031, 1444, 434, 2176, 680, 23, 130, 232, 17, 6441, 1442, 2348, 3151, 2, 251, 108, 50, 87, 125, 1, 21, 542, 3, 1431, 1026, 4127, 4, 1, 469, 1, 32, 1, 1977, 848, 53, 2785, 5, 1232, 6640, 2130, 3467, 533, 4, 8058, 265, 15, 55, 120, 1, 5093, 3, 501, 756, 1, 5093, 469, 7538, 32, 1794, 4945, 7171, 5, 3297, 1, 52, 2594, 468, 706, 514, 4, 1295, 3, 1, 1031, 469, 9585, 32, 2304, 5869, 5342, 4326, 1, 3533, 5, 1101, 5108, 3, 4916, 5, 6101, 640, 2454, 109, 8, 2188, 4, 3253, 3, 397, 1299, 2863, 13, 374, 1402, 3, 3137, 8390, 1, 3245, 42, 2806, 55, 1, 469, 1, 32, 2451, 9195, 601, 1637, 1, 1, 1648, 5, 14, 125, 7, 1, 4530, 153, 48, 261, 472, 189, 472, 298, 29, 1, 1, 1, 1, 218, 2134, 368, 1, 469, 7538, 32, 2191, 8835, 2191, 4, 570, 1, 1569, 8169, 9083, 198, 3194, 5414, 1888, 25, 285, 1, 7256, 4362, 469, 1, 32, 353, 7, 448, 3, 348, 1119, 1, 693, 3891, 1, 2643, 693, 9242, 2636, 4, 1442, 21, 944, 12, 353, 469, 1, 32, 5832, 5296, 227, 1, 524, 1977, 497, 3, 837, 1, 5832, 7, 570, 380, 28, 148, 373, 19, 1, 1804, 469, 1, 32, 404, 111, 1031, 1131, 468, 1, 3, 586, 1232, 539, 2176, 3754, 5, 570, 577, 1, 2176, 3880, 5, 577, 1, 1725, 1973, 1, 3, 952, 17, 1, 469, 1, 32, 6957, 111, 1, 1, 1, 9243, 6786, 348, 485, 228, 1, 4, 1, 863, 1, 8, 6925, 403, 181, 7, 1, 49, 1, 1813, 469, 8834, 32, 1036, 131, 5295, 2176, 4158, 2994, 5, 2176, 3946, 449, 338, 175, 5, 4062, 1, 546, 4, 175, 5, 1888, 1178, 104, 2729, 764, 276, 182, 707, 515, 5, 11, 132, 120, 276, 415, 730, 127, 132, 6731, 1, 2176, 99, 469, 1, 32, 6172, 1477, 2176, 4158, 2524, 4, 1652, 1442, 449, 48, 6172, 1477, 957, 1111, 17, 271, 1616, 1066, 8, 563, 4632, 95, 280, 1, 3, 1, 6467, 390, 5, 1, 8, 95, 2688, 754, 300, 469, 1, 32, 1202, 7513, 2176, 2122, 2057, 5, 2961, 4326, 845, 7, 1, 1, 1, 1452, 517, 6, 97, 715, 8833, 469, 8242, 32, 1164, 5, 2395, 1, 1, 1, 1, 517, 6, 97, 715, 8833, 305, 184, 6545, 469, 1, 1202, 8242, 32, 32, 4300, 715, 1417, 380, 82, 524, 4291, 6545, 469, 1, 32, 1, 715, 8574, 3614, 1, 97, 4291, 6545, 469, 1, 32, 1, 715, 48, 261, 472, 117, 305, 517, 1080, 469, 7538, 32, 407, 2176, 111, 8340, 1, 3071, 21, 1038, 407, 28, 2, 2994, 5, 539, 1558, 97, 1, 4876, 692, 3786, 633, 2265, 1, 8, 245, 65, 4, 476, 155, 1, 1, 148, 180, 1, 85, 93, 1499, 3, 327, 6840, 19, 3, 260, 6, 623, 5, 2, 9665, 1780, 155, 1, 19, 45, 31, 8, 359, 4090, 130, 3, 32, 359, 184, 34, 28, 2, 2994, 5, 539, 1558, 97, 633, 305, 184, 1, 126, 5, 11, 133, 9, 46, 3, 2, 417, 4, 860, 5, 2, 2230, 209, 17, 4463, 3608, 292, 19, 612, 9, 851]\n",
            "Padded shape: (51269, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Commit 3: Label preparation and saving features ---\n",
        "\n",
        "# 8. Labels\n",
        "y = df['label'].astype(int).values\n",
        "\n",
        "# 9. Train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 10. Save for model training\n",
        "np.save(\"data/X_train.npy\", X_train)\n",
        "np.save(\"data/X_test.npy\", X_test)\n",
        "np.save(\"data/y_train.npy\", y_train)\n",
        "np.save(\"data/y_test.npy\", y_test)\n",
        "\n",
        "print(\"✅ Tokenization & features saved:\")\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train distribution:\", np.bincount(y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zza6p-ngiM3h",
        "outputId": "0fbc31af-75ac-4cf8-8fad-856d5f18b7ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Tokenization & features saved:\n",
            "X_train shape: (41015, 200)\n",
            "y_train distribution: [24407 16608]\n"
          ]
        }
      ]
    }
  ]
}