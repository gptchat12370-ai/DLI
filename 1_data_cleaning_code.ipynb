{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlDS0tSPv/4f/IV7i12RhE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamedseklani/DLI/blob/main/1_data_cleaning_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mgnPH8pHinoa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "663e28be-aa3f-4b14-e8db-d8c33156eb05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'DLI' already exists and is not an empty directory.\n",
            "/content/DLI\n"
          ]
        }
      ],
      "source": [
        "!git config --global user.email \"mohamedseklani8@gmail.com\"\n",
        "!git config --global user.name \"mohamedseklani\"\n",
        "\n",
        "!git clone https://github.com/mohamedseklani/DLI\n",
        "%cd DLI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Commit 1: Initial load and null cleanup ---\n",
        "\n",
        "# 1) Setup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv, sys\n",
        "\n",
        "# Increase limit for very long email bodies\n",
        "csv.field_size_limit(sys.maxsize)\n",
        "\n",
        "# Pandas display settings\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# 2) Data Loading (robust)\n",
        "# Using on_bad_lines='skip' instead of deprecated error_bad_lines\n",
        "df = pd.read_csv(\n",
        "    \"/content/DLI/TREC-05.csv\",  # <-- adjust path to your file\n",
        "    engine=\"python\",\n",
        "    on_bad_lines=\"skip\",\n",
        "    sep=None,  # autodetect delimiter\n",
        "    encoding=\"utf-8\",\n",
        "    encoding_errors=\"replace\",  # handle weird characters\n",
        "    dtype=str  # read all as string first\n",
        ")\n",
        "\n",
        "print(\"Initial Shape:\", df.shape)\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# 3) Preprocessing - Remove nulls in key columns\n",
        "# Convert label and urls to numeric (coerce errors to NaN)\n",
        "if \"label\" in df.columns:\n",
        "    df[\"label\"] = pd.to_numeric(df[\"label\"], errors=\"coerce\")\n",
        "if \"urls\" in df.columns:\n",
        "    df[\"urls\"] = pd.to_numeric(df[\"urls\"], errors=\"coerce\")\n",
        "\n",
        "# Drop rows where body, subject, or label is missing\n",
        "required_cols = [c for c in [\"body\", \"subject\", \"label\"] if c in df.columns]\n",
        "df.dropna(subset=required_cols, inplace=True)\n",
        "\n",
        "# Fill missing urls with 0 and ensure integer type\n",
        "if \"urls\" in df.columns:\n",
        "    df[\"urls\"] = df[\"urls\"].fillna(0)\n",
        "    df[\"urls\"] = np.maximum(df[\"urls\"].astype(float), 0).astype(int)\n",
        "\n",
        "# Strip extra whitespace from text fields\n",
        "for col in [\"subject\", \"body\"]:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].astype(str).str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
        "\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "print(\"After cleaning Shape:\", df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCaLAUMOMjkQ",
        "outputId": "2f7edceb-0195-4b15-f07e-801a06682641"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Shape: (53875, 7)\n",
            "sender        13\n",
            "receiver    2627\n",
            "date        2376\n",
            "subject     2472\n",
            "body        1214\n",
            "label       1341\n",
            "urls        1342\n",
            "dtype: int64\n",
            "After cleaning Shape: (51264, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "os.makedirs(\"notebooks\", exist_ok=True)\n",
        "\n",
        "# Save cleaned CSV inside data/\n",
        "df.to_csv(\"data/cleaned_data.csv\", index=False)\n",
        "\n",
        "# Optional: Save notebook (if working inside Colab manually, skip this)"
      ],
      "metadata": {
        "id": "4z25a-kRUZaQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIZPzzH1WOiJ",
        "outputId": "46e964e4-1bb6-46e0-c1b3-34219033bd39"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes to be committed:\n",
            "  (use \"git restore --staged <file>...\" to unstage)\n",
            "\t\u001b[32mnew file:   data/cleaned_data.csv\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mTREC-05.csv\u001b[m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save notebook in Colab manually\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download(\"1_data_cleaning.ipynb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "9PO7-8ZbZRJD",
        "outputId": "bf2047c8-a0f2-4f57-ccc2-75a4a21232c4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Cannot find file: 1_data_cleaning.ipynb",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2142276887.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1_data_cleaning.ipynb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    231\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot find file: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: 1_data_cleaning.ipynb"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p notebooks\n",
        "!mv 1_data_cleaning.ipynb notebooks/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HL_m-tAY3l3",
        "outputId": "6d48eb97-7958-4573-f0d9-2355ebdb4968"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat '1_data_cleaning.ipynb': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure he is inside his forked repo directory in Colab or terminal\n",
        "!git add data/cleaned_data.csv notebooks/1_data_cleaning.ipynb\n",
        "!git commit -m \"Commit 1: Cleaned and saved dataset\"\n",
        "!git push origin main  # Push to his fork's main branch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bKtLwkBST0y",
        "outputId": "7c236358-a006-496d-f241-38eb6d57099f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: pathspec 'notebooks/1_data_cleaning.ipynb' did not match any files\n",
            "[main 2374209] Commit 1: Cleaned and saved dataset\n",
            " 1 file changed, 51265 insertions(+)\n",
            " create mode 100644 data/cleaned_data.csv\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Commit 2: Class distribution and word cloud ---\n",
        "\n",
        "# Class Distribution\n",
        "label_counts = df['label'].value_counts()\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.barplot(x=label_counts.index, y=label_counts.values)\n",
        "plt.xticks([0, 1], ['Legitimate (0)', 'Phishing (1)'])\n",
        "plt.title(\"Class Distribution\")\n",
        "plt.xlabel(\"Email Type\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"results/class_distribution.png\")\n",
        "plt.show()\n",
        "\n",
        "# Word Clouds\n",
        "phish_text = ' '.join(df[df['label'] == 1]['body'].dropna().values)\n",
        "legit_text = ' '.join(df[df['label'] == 0]['body'].dropna().values)\n",
        "\n",
        "phish_wc = WordCloud(width=800, height=400, background_color='white').generate(phish_text)\n",
        "legit_wc = WordCloud(width=800, height=400, background_color='white').generate(legit_text)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(phish_wc, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Word Cloud - Phishing Emails\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"results/phishing_wordcloud.png\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(legit_wc, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Word Cloud - Legitimate Emails\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"results/legit_wordcloud.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "61MJBUIiSDju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add results/class_distribution.png results/phishing_wordcloud.png results/legit_wordcloud.png\n",
        "!git commit -m \"Commit 2: Added class distribution and word cloud visualizations\"\n",
        "!git push origin main"
      ],
      "metadata": {
        "id": "XOG09OYXSdyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Commit 3: Saved cleaned dataset for next stage ---\n",
        "\n",
        "# Save Cleaned Data\n",
        "df.to_csv(\"data/cleaned_data.csv\", index=False)\n",
        "print(\"Cleaned data saved to 'data/cleaned_data.csv'.\")\n",
        "\n",
        "# Summary\n",
        "print(\"Final Class Counts:\")\n",
        "print(df['label'].value_counts())\n",
        "print(\"Preview:\")\n",
        "print(df[['subject', 'label']].head())"
      ],
      "metadata": {
        "id": "m6RJ5lH8SEOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add data/cleaned_data.csv notebooks/1_data_cleaning.ipynb\n",
        "!git commit -m \"Commit 3: Final cleaned dataset export and stats summary\"\n",
        "!git push origin main"
      ],
      "metadata": {
        "id": "RAvKBWzoSiqk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}